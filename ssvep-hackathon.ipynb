{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11664382,"sourceType":"datasetVersion","datasetId":7320442}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"committed-theme","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport mat73\nfrom scipy.linalg import dft\nfrom scipy import linalg\nfrom scipy.signal import butter, iirnotch, lfilter, freqz, filtfilt\nfrom scipy.fft import fft, fftfreq\nimport warnings\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:34:52.507464Z","iopub.execute_input":"2025-05-03T18:34:52.508032Z","iopub.status.idle":"2025-05-03T18:34:53.278716Z","shell.execute_reply.started":"2025-05-03T18:34:52.508005Z","shell.execute_reply":"2025-05-03T18:34:53.277972Z"}},"outputs":[],"execution_count":3},{"id":"incorporated-evanescence","cell_type":"code","source":"with open('/kaggle/input/br41n-ssvep-data/ssvep/classInfo_4_5.m') as f:\n    targets_str= f.read().split('\\n')\n\ntargets=[]\nfor label in targets_str[:-1]:\n    targets.append(list(map(int,label.split(' '))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:34:57.517521Z","iopub.execute_input":"2025-05-03T18:34:57.518146Z","iopub.status.idle":"2025-05-03T18:34:57.530761Z","shell.execute_reply.started":"2025-05-03T18:34:57.518112Z","shell.execute_reply":"2025-05-03T18:34:57.530028Z"}},"outputs":[],"execution_count":4},{"id":"directed-princeton","cell_type":"code","source":"subject= 1\nsub1_train1_data = '/kaggle/input/br41n-ssvep-data/ssvep/subject_1_fvep_led_training_1.mat'\nsub1_train2_data = '/kaggle/input/br41n-ssvep-data/ssvep/subject_1_fvep_led_training_2.mat'\nsub2_train1_data = '/kaggle/input/br41n-ssvep-data/ssvep/subject_2_fvep_led_training_1.mat'\nsub2_train2_data = '/kaggle/input/br41n-ssvep-data/ssvep/subject_2_fvep_led_training_2.mat'\n\ndata_dict_sub1_train1 = mat73.loadmat(sub1_train1_data)\ndata_dict_sub1_train2 = mat73.loadmat(sub1_train2_data)\ndata_dict_sub2_train1 = mat73.loadmat(sub2_train1_data)\ndata_dict_sub2_train2 = mat73.loadmat(sub2_train2_data)\n\nprint(data_dict_sub1_train1.keys(), data_dict_sub1_train2.keys(), data_dict_sub2_train1.keys(), data_dict_sub2_train2.keys())\n\ndata_sub1_train1 = data_dict_sub1_train1['y']\ndata_sub1_train2 = data_dict_sub1_train2['y']\ndata_sub2_train1 = data_dict_sub2_train1['y']\ndata_sub2_train2 = data_dict_sub2_train2['y']\n\nprint(data_sub1_train1.shape, data_sub1_train2.shape, data_sub2_train1.shape, data_sub2_train2.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:34:58.497736Z","iopub.execute_input":"2025-05-03T18:34:58.498425Z","iopub.status.idle":"2025-05-03T18:34:59.022190Z","shell.execute_reply.started":"2025-05-03T18:34:58.498398Z","shell.execute_reply":"2025-05-03T18:34:59.021391Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['y']) dict_keys(['y']) dict_keys(['y']) dict_keys(['y'])\n(11, 57728) (11, 58112) (11, 58757) (11, 57697)\n","output_type":"stream"}],"execution_count":5},{"id":"dirty-affiliate","cell_type":"code","source":"print((data_sub1_train1[10]==0).sum(), (data_sub1_train1[10]==1).sum(), (data_sub1_train1[10]==2).sum(), (data_sub1_train1[10]==3).sum(), (data_sub1_train1[10]==4).sum())\nprint((data_sub1_train2[10]==0).sum(), (data_sub1_train2[10]==1).sum(), (data_sub1_train2[10]==2).sum(), (data_sub1_train2[10]==3).sum(), (data_sub1_train2[10]==4).sum())\nprint((data_sub2_train1[10]==0).sum(), (data_sub2_train1[10]==1).sum(), (data_sub2_train1[10]==2).sum(), (data_sub2_train1[10]==3).sum(), (data_sub2_train1[10]==4).sum())\nprint((data_sub2_train2[10]==0).sum(), (data_sub2_train2[10]==1).sum(), (data_sub2_train2[10]==2).sum(), (data_sub2_train2[10]==3).sum(), (data_sub2_train2[10]==4).sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:35:00.633715Z","iopub.execute_input":"2025-05-03T18:35:00.634247Z","iopub.status.idle":"2025-05-03T18:35:00.647567Z","shell.execute_reply.started":"2025-05-03T18:35:00.634219Z","shell.execute_reply":"2025-05-03T18:35:00.646718Z"}},"outputs":[{"name":"stdout","text":"51072 0 0 6656 0\n50832 156 0 6344 780\n32289 5408 4212 1768 15080\n29097 3328 2912 2548 19812\n","output_type":"stream"}],"execution_count":6},{"id":"advanced-madrid","cell_type":"code","source":"def get_trigger_intervals(data):\n    intervals_start= []\n    intervals_end= []\n\n    for i in range(0,len(data[9])-1):\n        if data[9,i]==0 and data[9,i+1]==1:\n            intervals_start.append(i+1)\n        if data[9,i]==1 and data[9,i+1]==0:\n            intervals_end.append(i+1)\n    assert len(intervals_start)== len(intervals_end)\n\n    import numpy as np\n    intervals = np.array([intervals_start, intervals_end]).T\n\n    return intervals\n\ndef get_label_array(data):\n    intervals = get_trigger_intervals(data) \n    labels = np.zeros((data.shape[1]))\n    class_=1\n    for interval in intervals:\n        labels[interval[0]:interval[1]]= class_\n        class_+=1\n        if class_==5:class_=1\n    return labels\n\ndef get_segment(data_channel, intervals):\n    output = []\n    if len(data_channel.shape)==1:\n        for interval in intervals:\n            output.append(data_channel[interval[0]: interval[1]])\n    \n    elif len(data_channel.shape)==2:\n        for interval in intervals:\n            output.append(data_channel[:,interval[0]: interval[1]])\n    return np.array(output)\n\ndef create_dataset(sample_eeg, sample_labels, window_size=10):\n    eegs=[]\n    labels=[]\n    for idx in range(len(sample_eeg)):\n        eeg_chunk = sample_eeg[idx]\n        label_chunk= sample_labels[idx]\n        for i in range(0, eeg_chunk.shape[1]- window_size, window_size):\n            eegs.append(eeg_chunk[:,i:i+window_size])\n            labels.append(label_chunk[i])\n            for k in range(len(label_chunk)-1):\n                assert label_chunk[k]==label_chunk[k+1]\n    return np.array(eegs), np.array(labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:35:02.291479Z","iopub.execute_input":"2025-05-03T18:35:02.291992Z","iopub.status.idle":"2025-05-03T18:35:02.300202Z","shell.execute_reply.started":"2025-05-03T18:35:02.291967Z","shell.execute_reply":"2025-05-03T18:35:02.299416Z"}},"outputs":[],"execution_count":7},{"id":"swedish-referral","cell_type":"code","source":"name1= \"data_sub1_train1\"\ndata1 = data_sub1_train1\n\nname2= \"data_sub1_train2\"\ndata2 = data_sub1_train2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:35:05.243772Z","iopub.execute_input":"2025-05-03T18:35:05.244080Z","iopub.status.idle":"2025-05-03T18:35:05.248185Z","shell.execute_reply.started":"2025-05-03T18:35:05.244049Z","shell.execute_reply":"2025-05-03T18:35:05.247324Z"}},"outputs":[],"execution_count":8},{"id":"pregnant-prompt","cell_type":"code","source":"def filter_eeg(eeg_signal):\n    b1, a1 = butter(N=6, Wn=[0.5, 30], btype='bandpass', fs=256)\n    b2, a2 = iirnotch(w0= 50, Q=30, fs=256)\n    \n    filtered_eeg = filtfilt(b1, a1, eeg_signal)\n    filtered_eeg2 = filtfilt(b2, a2, filtered_eeg)\n    return filtered_eeg2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:35:07.158120Z","iopub.execute_input":"2025-05-03T18:35:07.158378Z","iopub.status.idle":"2025-05-03T18:35:07.162929Z","shell.execute_reply.started":"2025-05-03T18:35:07.158360Z","shell.execute_reply":"2025-05-03T18:35:07.162178Z"}},"outputs":[],"execution_count":9},{"id":"western-discount","cell_type":"code","source":"def prep_data(data):\n    intervals = get_trigger_intervals(data)\n    labels = get_label_array(data)\n\n    samples_labels= get_segment(labels, intervals)\n    samples_lda_preds= get_segment(data[10], intervals)\n    samples_eeg= get_segment(data[1:9], intervals)\n\n    eegs,labels = create_dataset(samples_eeg, samples_labels, window_size=768) # window_size -> timestamps\n    eegs.shape, eegs[0].shape, labels.shape, labels[0]\n    \n    filtered_eegs= []\n    for eeg in eegs:\n        filtered_eegs.append(filter_eeg(eeg))\n    filtered_eegs= np.array(filtered_eegs)\n    \n    return filtered_eegs,labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:35:08.791638Z","iopub.execute_input":"2025-05-03T18:35:08.792332Z","iopub.status.idle":"2025-05-03T18:35:08.796971Z","shell.execute_reply.started":"2025-05-03T18:35:08.792307Z","shell.execute_reply":"2025-05-03T18:35:08.796211Z"}},"outputs":[],"execution_count":10},{"id":"ecological-scout","cell_type":"code","source":"filtered_eegs1,labels1 = prep_data(data1)\nfiltered_eegs2,labels2 = prep_data(data2)\n\nfiltered_eegs3 = np.append(filtered_eegs1,filtered_eegs2, axis=0)\nlabels3 = np.append(labels1, labels2, axis=0)\n\nprint(filtered_eegs1.shape,labels1.shape)\nprint(filtered_eegs2.shape,labels2.shape)\nprint(filtered_eegs3.shape,labels3.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:35:10.341922Z","iopub.execute_input":"2025-05-03T18:35:10.342197Z","iopub.status.idle":"2025-05-03T18:35:10.671974Z","shell.execute_reply.started":"2025-05-03T18:35:10.342175Z","shell.execute_reply":"2025-05-03T18:35:10.671381Z"}},"outputs":[{"name":"stdout","text":"(40, 8, 768) (40,)\n(40, 8, 768) (40,)\n(80, 8, 768) (80,)\n","output_type":"stream"}],"execution_count":11},{"id":"cooked-cause","cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"id":"stopped-allocation","cell_type":"code","source":"# for tsfresh\nfrom tsfresh import extract_relevant_features\nfrom tsfresh import extract_features, select_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:28.134924Z","iopub.execute_input":"2025-05-03T18:42:28.135204Z","iopub.status.idle":"2025-05-03T18:42:35.037824Z","shell.execute_reply.started":"2025-05-03T18:42:28.135186Z","shell.execute_reply":"2025-05-03T18:42:35.037043Z"}},"outputs":[],"execution_count":17},{"id":"medical-chorus","cell_type":"code","source":"# dfx = pd.DataFrame(columns = ['eeg1','eeg2','eeg3','eeg4','eeg5','eeg6','eeg7','eeg8','id'])\n# for i in range(filtered_eegs.shape[0]):\n#     if i == 0:\n#         temp = filtered_eegs[i].T\n#         ids = np.pad(np.array([i]),(0,filtered_eegs[i].shape[1]-1),'constant',constant_values = i)\n#         print(temp.shape, ids.shape)\n#         continue\n    \n#     temp = np.append(temp, filtered_eegs[i].T, axis=0)\n#     ids = np.append(ids,np.pad(np.array([i]),(0,filtered_eegs[i].shape[1]-1),'constant',constant_values = i))\n#     print(temp.shape, ids.shape)\n# dfx_arr = np.append(temp,ids.reshape((ids.shape[0],1)), axis=1)\n# dfx_arr.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:35.038897Z","iopub.execute_input":"2025-05-03T18:42:35.039424Z","iopub.status.idle":"2025-05-03T18:42:35.042699Z","shell.execute_reply.started":"2025-05-03T18:42:35.039405Z","shell.execute_reply":"2025-05-03T18:42:35.042000Z"}},"outputs":[],"execution_count":18},{"id":"absent-rings","cell_type":"code","source":"def ready_for_tsf(eegs, labels):\n    # generatig X dataframe\n    dfx = pd.DataFrame(columns = ['eeg1','eeg2','eeg3','eeg4','eeg5','eeg6','eeg7','eeg8','id'])\n    for i in range(eegs.shape[0]):\n        if i == 0:\n            temp = eegs[i].T\n            ids = np.pad(np.array([i]),(0,eegs[i].shape[1]-1),'constant',constant_values = i)\n            print(temp.shape, ids.shape)\n            continue\n    \n        temp = np.append(temp, eegs[i].T, axis=0)\n        ids = np.append(ids,np.pad(np.array([i]),(0,eegs[i].shape[1]-1),'constant',constant_values = i))\n#     print(temp.shape, ids.shape)\n    for j in range(8):\n        dfx['eeg'+str(j+1)] = temp[:,j]\n    print(dfx)\n    dfx['id'] = ids\n\n    # generate a unique id for each movement based on gesture and iteration values\n    dfy = pd.DataFrame()\n    dfy['id']  = ids\n    # dropping ALL duplicte values\n    dfy = dfy.drop_duplicates()\n    dfy['y'] \t= labels\n\n    # save files\n#     print(dfy)\n#     save_file(df, configs(save_folder,'file_tsf_input_x'))\n#     save_file(dfy, configs(save_folder,'file_tsf_input_y'))\n    return dfx,dfy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:39.918489Z","iopub.execute_input":"2025-05-03T18:42:39.919085Z","iopub.status.idle":"2025-05-03T18:42:39.925205Z","shell.execute_reply.started":"2025-05-03T18:42:39.919060Z","shell.execute_reply":"2025-05-03T18:42:39.924309Z"}},"outputs":[],"execution_count":19},{"id":"chicken-monaco","cell_type":"code","source":"def run_tsfresh(eegs,labels):\n\n    dfx,dfy = ready_for_tsf(eegs, labels)\n    y =  pd.Series(data=dfy[\"y\"].values, index=dfy[\"id\"].values)\n    \n    #   # Removing mean and scaling - if the following section is needed uncomment it\n#     grouped = dfx.groupby(dfx.id)\n#     ids = dfx['id']\n#     ids = list(set(ids))\n#     ids.sort()\n#     for i in ids:\n#         if i == ids[0]:\n#             X = scaled_gesture(grouped,i)\n#             continue\n\n#         scaled_g = scaled_gesture(grouped,i)\n#         X = X.append(scaled_g, ignore_index=True)\n\n\n#     print(X.head())\n#     print(y.head())\n\n    fc_parameters = {\n    \"spkt_welch_density\":  [{\"coeff\": 9}, {\"coeff\": 10}, {\"coeff\": 12}, {\"coeff\": 15}]\n    }\n\n    warnings.simplefilter(\"ignore\")\n#     features_filtered = extract_relevant_features(dfx, y, column_id='id',n_jobs=0)\n    features_filtered = extract_features(dfx, default_fc_parameters=fc_parameters, column_id='id')\n    print(features_filtered.head())\n    print('TSF finished')\n    return features_filtered","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:42.655512Z","iopub.execute_input":"2025-05-03T18:42:42.656026Z","iopub.status.idle":"2025-05-03T18:42:42.661106Z","shell.execute_reply.started":"2025-05-03T18:42:42.655999Z","shell.execute_reply":"2025-05-03T18:42:42.660304Z"}},"outputs":[],"execution_count":20},{"id":"8b4d96d8","cell_type":"markdown","source":"## Test to model","metadata":{}},{"id":"genuine-charm","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom tsfresh import extract_features\nfrom tsfresh.utilities.dataframe_functions import make_forecasting_frame\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:49.843291Z","iopub.execute_input":"2025-05-03T18:42:49.843557Z","iopub.status.idle":"2025-05-03T18:42:50.017082Z","shell.execute_reply.started":"2025-05-03T18:42:49.843537Z","shell.execute_reply":"2025-05-03T18:42:50.016223Z"}},"outputs":[],"execution_count":21},{"id":"f620bc13","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tsfresh import extract_features\nfrom tsfresh.utilities.dataframe_functions import impute\nfrom tqdm import tqdm\n\ndef run_tsfresh(eegs, labels):\n    # eegs: list of shape (n_samples, n_channels, n_times)\n    df_list = []\n    \n    for i in tqdm(range(len(eegs)), desc=\"Feature Extraction\"):\n        eeg = eegs[i]\n        n_channels, n_times = eeg.shape\n        for ch in range(n_channels):\n            for t in range(n_times):\n                df_list.append({\n                    \"id\": i,\n                    \"time\": t,\n                    \"value\": eeg[ch, t],\n                    \"kind\": f\"ch{ch}\"\n                })\n\n    df_all = pd.DataFrame(df_list)\n    \n    features = extract_features(\n        df_all,\n        column_id=\"id\",\n        column_sort=\"time\",\n        column_kind=\"kind\",\n        column_value=\"value\",\n        n_jobs=0,  # set to 0 to disable multiprocessing (simpler debugging)\n    )\n\n    impute(features)\n    return features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:52.752664Z","iopub.execute_input":"2025-05-03T18:42:52.753267Z","iopub.status.idle":"2025-05-03T18:42:52.758855Z","shell.execute_reply.started":"2025-05-03T18:42:52.753247Z","shell.execute_reply":"2025-05-03T18:42:52.758127Z"}},"outputs":[],"execution_count":22},{"id":"d2436f56","cell_type":"code","source":"def ready_for_sklearn(eegs, labels, name):\n    dfx = run_tsfresh(eegs, labels)\n    dfx.columns = dfx.columns.str.replace('\"', '#')\n    y = ['L' + str(int(l)) for l in labels]\n    dfx['y'] = y\n    dfx.to_csv(f'ssvep/{name}_input.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:56.038139Z","iopub.execute_input":"2025-05-03T18:42:56.039052Z","iopub.status.idle":"2025-05-03T18:42:56.043317Z","shell.execute_reply.started":"2025-05-03T18:42:56.039023Z","shell.execute_reply":"2025-05-03T18:42:56.042548Z"}},"outputs":[],"execution_count":23},{"id":"6fee72de","cell_type":"code","source":"def select_features(name, k=30):\n    df = pd.read_csv(f'ssvep/{name}_input.csv')\n    X = df.drop(columns=['y'])\n    y = df['y']\n    \n    selector = SelectKBest(score_func=mutual_info_classif, k=k)\n    X_new = selector.fit_transform(X, y)\n    selected_columns = X.columns[selector.get_support()]\n    \n    X_selected = pd.DataFrame(X_new, columns=selected_columns)\n    X_selected['y'] = y\n    X_selected.to_csv(f'ssvep/{name}_selected.csv', index=False)\n    \n    print(f'Selected top {k} features: {list(selected_columns)}')\n    print('Filtered dataset shape:', X_selected.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:42:58.915501Z","iopub.execute_input":"2025-05-03T18:42:58.916266Z","iopub.status.idle":"2025-05-03T18:42:58.920968Z","shell.execute_reply.started":"2025-05-03T18:42:58.916232Z","shell.execute_reply":"2025-05-03T18:42:58.920396Z"}},"outputs":[],"execution_count":24},{"id":"a4d05f1b","cell_type":"code","source":"def run_model(X, y, clf, model_name):\n    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    scores = cross_val_score(clf, X, y, cv=skf, scoring='accuracy')\n    print(f\"{model_name}: Accuracy = {scores.mean():.4f} ± {scores.std():.4f}\")\n    return scores\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:43:00.986872Z","iopub.execute_input":"2025-05-03T18:43:00.987197Z","iopub.status.idle":"2025-05-03T18:43:00.991540Z","shell.execute_reply.started":"2025-05-03T18:43:00.987177Z","shell.execute_reply":"2025-05-03T18:43:00.990996Z"}},"outputs":[],"execution_count":25},{"id":"3610a8af","cell_type":"code","source":"import os\n\n# Create the folder if it doesn't exist\nos.makedirs('kaggle/working/ssvep', exist_ok=True)\n\ndef classify_models(name, use_selected=False):\n    if use_selected:\n        df = pd.read_csv(f'ssvep/{name}_selected.csv')\n    else:\n        df = pd.read_csv(f'ssvep/{name}_input.csv')\n    \n    X = df.drop(columns=['y'])\n    y = df['y']\n    \n    print(f'Using {\"selected\" if use_selected else \"all\"} features - shape: {X.shape}')\n    \n    run_model(X, y, SVC(kernel='linear'), 'SVM')\n    run_model(X, y, GaussianNB(), 'Naive Bayes')\n    run_model(X, y, KNeighborsClassifier(n_neighbors=3), 'KNN')\n    run_model(X, y, LogisticRegression(max_iter=1000), 'Logistic Regression')\n    run_model(X, y, RandomForestClassifier(n_estimators=100), 'Random Forest')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:53:06.737289Z","iopub.execute_input":"2025-05-03T18:53:06.738032Z","iopub.status.idle":"2025-05-03T18:53:06.743674Z","shell.execute_reply.started":"2025-05-03T18:53:06.738002Z","shell.execute_reply":"2025-05-03T18:53:06.743045Z"}},"outputs":[],"execution_count":28},{"id":"92eaadc4","cell_type":"code","source":"# Example usage\nname1 = 'sample_subject'\n\n# filtered_eegs1 and labels1 should be defined previously\nready_for_sklearn(filtered_eegs1, labels1, name1)\nselect_features(name1, k=30)\nclassify_models(name1, use_selected=False)\nclassify_models(name1, use_selected=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:53:18.195601Z","iopub.execute_input":"2025-05-03T18:53:18.196323Z"}},"outputs":[{"name":"stderr","text":"Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 349.93it/s]\nFeature Extraction:  81%|████████  | 259/320 [04:42<01:06,  1.09s/it]","output_type":"stream"}],"execution_count":null},{"id":"impossible-generator","cell_type":"markdown","source":"# Classification","metadata":{}},{"id":"annual-programmer","cell_type":"markdown","source":"# LDA","metadata":{}},{"id":"sacred-cleaner","cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.713241Z","iopub.status.idle":"2025-05-03T18:48:54.713489Z","shell.execute_reply.started":"2025-05-03T18:48:54.713377Z","shell.execute_reply":"2025-05-03T18:48:54.713389Z"}},"outputs":[],"execution_count":null},{"id":"neural-picture","cell_type":"code","source":"# train = s1 run1\n# test = s2 run2\nX_train = run_tsfresh(filtered_eegs1,labels1)\ny_train = labels1\nX_test = run_tsfresh(filtered_eegs2,labels2)\ny_test = labels2\nocolumns = X_train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.714649Z","iopub.status.idle":"2025-05-03T18:48:54.714912Z","shell.execute_reply.started":"2025-05-03T18:48:54.714777Z","shell.execute_reply":"2025-05-03T18:48:54.714786Z"}},"outputs":[],"execution_count":null},{"id":"expensive-robertson","cell_type":"code","source":"X = run_tsfresh(filtered_eegs1,labels1)\nocolumns = X.columns\ny = labels1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.715864Z","iopub.status.idle":"2025-05-03T18:48:54.716156Z","shell.execute_reply.started":"2025-05-03T18:48:54.716015Z","shell.execute_reply":"2025-05-03T18:48:54.716029Z"}},"outputs":[],"execution_count":null},{"id":"female-folks","cell_type":"code","source":"# create the lda model\nmodel = LinearDiscriminantAnalysis()\n\n# define model evaluation method\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate model\nscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n# summarize result\nprint('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.717384Z","iopub.status.idle":"2025-05-03T18:48:54.717617Z","shell.execute_reply.started":"2025-05-03T18:48:54.717518Z","shell.execute_reply":"2025-05-03T18:48:54.717527Z"}},"outputs":[],"execution_count":null},{"id":"recognized-germany","cell_type":"code","source":"# define model evaluation method\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid\ngrid = dict()\ngrid['solver'] = ['svd', 'lsqr', 'eigen']\n# define search\nsearch = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n# perform the search\nresults = search.fit(X, y)\n# summarize\n\nprint('Mean Accuracy: %.3f' % results.best_score_)\nprint('Config: %s' % results.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.719390Z","iopub.status.idle":"2025-05-03T18:48:54.719632Z","shell.execute_reply.started":"2025-05-03T18:48:54.719519Z","shell.execute_reply":"2025-05-03T18:48:54.719531Z"}},"outputs":[],"execution_count":null},{"id":"variable-absolute","cell_type":"markdown","source":"# SVM","metadata":{}},{"id":"apparent-oklahoma","cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.decomposition import PCA                 # for dimensionality reduction using PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport matplotlib.pyplot as plt \nimport seaborn as sns            # visualization tool\nimport matplotlib.cm as cm       # for colour mapping to use for the pca plots","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.720538Z","iopub.status.idle":"2025-05-03T18:48:54.720813Z","shell.execute_reply.started":"2025-05-03T18:48:54.720654Z","shell.execute_reply":"2025-05-03T18:48:54.720669Z"}},"outputs":[],"execution_count":null},{"id":"introductory-button","cell_type":"code","source":"scaler = preprocessing.MinMaxScaler()   # since the data set is not gaussian\nscaled_df = scaler.fit_transform(X_train)\nX_train = pd.DataFrame(scaled_df,columns = ocolumns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns = ocolumns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.721684Z","iopub.status.idle":"2025-05-03T18:48:54.721990Z","shell.execute_reply.started":"2025-05-03T18:48:54.721800Z","shell.execute_reply":"2025-05-03T18:48:54.721815Z"}},"outputs":[],"execution_count":null},{"id":"backed-honduras","cell_type":"code","source":"svclassifier = SVC(kernel = 'linear',C = 1, gamma = 1)\n# C = 1.0, gamma = 1.0 for linear kernel - selected using GridSearchCV - for dataset 40\n# C = 1, gamma = 1 for rbf kernel - selected using GridSearchCV - for dataset 40\n# C = 0.01, gamma = 10 for rbf kernel - selected using GridSearchCV - for dataset 80\n# C = 10, gamma = 1 for linear kernel - selected using GridSearchCV - for dataset 80\n\nsvclassifier.fit(X_train,y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.723047Z","iopub.status.idle":"2025-05-03T18:48:54.723348Z","shell.execute_reply.started":"2025-05-03T18:48:54.723194Z","shell.execute_reply":"2025-05-03T18:48:54.723209Z"}},"outputs":[],"execution_count":null},{"id":"dietary-swaziland","cell_type":"code","source":"y_pred = svclassifier.predict(X_test)\n#result = [y_pred[i] == y_test[i] for i in range(len(y_test))]\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(confusion_matrix(y_test,y_pred), annot=True, linewidths=.1, fmt= '.0f',ax=ax).set_ylim(4,0)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Actual Class\")\nplt.show()\nprint(list(y_test),list(y_pred))\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.724629Z","iopub.status.idle":"2025-05-03T18:48:54.724907Z","shell.execute_reply.started":"2025-05-03T18:48:54.724760Z","shell.execute_reply":"2025-05-03T18:48:54.724772Z"}},"outputs":[],"execution_count":null},{"id":"pretty-behavior","cell_type":"code","source":"param_grid = {'C': [0.01,0.1, 1, 10, 100,1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.00001, 10,100]}\nclf_grid = GridSearchCV(SVC(kernel = 'linear'), param_grid)\nclf_grid.fit(X_train, y_train)\nprint(\"Best Parameters:\\n\", clf_grid.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.725754Z","iopub.status.idle":"2025-05-03T18:48:54.726017Z","shell.execute_reply.started":"2025-05-03T18:48:54.725903Z","shell.execute_reply":"2025-05-03T18:48:54.725915Z"}},"outputs":[],"execution_count":null},{"id":"parental-colonial","cell_type":"code","source":"scaler = preprocessing.MinMaxScaler()   # since the data set is not gaussian\nscaled_df = scaler.fit_transform(X)\nX = pd.DataFrame(scaled_df,columns = ocolumns)\nX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.727023Z","iopub.status.idle":"2025-05-03T18:48:54.727321Z","shell.execute_reply.started":"2025-05-03T18:48:54.727169Z","shell.execute_reply":"2025-05-03T18:48:54.727182Z"}},"outputs":[],"execution_count":null},{"id":"organized-curve","cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20, stratify = y)\n\nsvclassifier = SVC(kernel = 'linear',C = 1, gamma = 1)\n# C = 1.0, gamma = 1.0 for linear kernel - selected using GridSearchCV - for dataset 40\n# C = 1, gamma = 1 for rbf kernel - selected using GridSearchCV - for dataset 40\n# C = 0.01, gamma = 10 for rbf kernel - selected using GridSearchCV - for dataset 80\n# C = 10, gamma = 1 for linear kernel - selected using GridSearchCV - for dataset 80\n\nsvclassifier.fit(X_train,y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.727994Z","iopub.status.idle":"2025-05-03T18:48:54.728238Z","shell.execute_reply.started":"2025-05-03T18:48:54.728139Z","shell.execute_reply":"2025-05-03T18:48:54.728149Z"}},"outputs":[],"execution_count":null},{"id":"cosmetic-devon","cell_type":"code","source":"y_pred = svclassifier.predict(X_test)\n#result = [y_pred[i] == y_test[i] for i in range(len(y_test))]\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(confusion_matrix(y_test,y_pred), annot=True, linewidths=.1, fmt= '.0f',ax=ax).set_ylim(4,0)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Actual Class\")\nplt.show()\nprint(list(y_test),list(y_pred))\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.729301Z","iopub.status.idle":"2025-05-03T18:48:54.729566Z","shell.execute_reply.started":"2025-05-03T18:48:54.729448Z","shell.execute_reply":"2025-05-03T18:48:54.729462Z"}},"outputs":[],"execution_count":null},{"id":"spoken-rogers","cell_type":"code","source":"param_grid = {'C': [0.01,0.1, 1, 10, 100,1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.00001, 10,100]}\nclf_grid = GridSearchCV(SVC(kernel = 'linear'), param_grid)\nclf_grid.fit(X, y)\nprint(\"Best Parameters:\\n\", clf_grid.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.730383Z","iopub.status.idle":"2025-05-03T18:48:54.730576Z","shell.execute_reply.started":"2025-05-03T18:48:54.730483Z","shell.execute_reply":"2025-05-03T18:48:54.730491Z"}},"outputs":[],"execution_count":null},{"id":"varying-lucas","cell_type":"code","source":"################  ALL_MODELS ######################\n\nimport sklearn\nfrom sklearn.ensemble import *\nfrom sklearn.neighbors import *\nfrom sklearn.linear_model import *\nfrom sklearn.svm import *\nfrom sklearn.tree import *\n\n\n# common models\nmodel1=KNeighborsClassifier()\nmodel2=RadiusNeighborsClassifier(radius=10)\nmodel3=PassiveAggressiveClassifier()\nmodel4=RidgeClassifier()\nmodel5=RidgeClassifierCV()\nmodel6=SGDClassifier()\nmodel7=LinearSVC()\nmodel8=NuSVC()\nmodel9=SVC()\nmodel10=DecisionTreeClassifier()\nmodel11=ExtraTreeClassifier()\n\n#models_from_ensemble\nmodel12=AdaBoostClassifier()\nmodel13=BaggingClassifier()\nmodel14=ExtraTreesClassifier(n_estimators=1000)\nmodel15=GradientBoostingClassifier()\nmodel16=RandomForestClassifier()\n\n# Using multiple models\n\nestimators=[('model2',model2),('model12',model12),('model14',model14) ]\n\nmodel17=StackingClassifier(estimators = estimators)\nmodel18=VotingClassifier(estimators=estimators)\n\n####################### all_models ############################\nmodels=[model1,model2,model3,model4,model5,model6,model7,model8,model9,model10,model11,\n        model12,model13,model14,model15,model16,model17,model18]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.731055Z","iopub.status.idle":"2025-05-03T18:48:54.731269Z","shell.execute_reply.started":"2025-05-03T18:48:54.731170Z","shell.execute_reply":"2025-05-03T18:48:54.731180Z"}},"outputs":[],"execution_count":null},{"id":"opposite-basement","cell_type":"code","source":"# TRAINING ALL THE MODELS\n\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\ni=0\nimportances=[]\nfor model in models:\n    i+=1\n    try:\n        model.fit(X_train,y_train)\n    except Exception as e: print('Error in model.fit >>>',e)\n    try:\n        pred=model.predict(X_test)\n    except Exception as e: print('Error in model.predict >>>',e)\n    print(str(i)+'___'+str(model.__class__)+(100-len(str(model.__class__)))*'>'+'__',accuracy_score(y_test,pred))\n    try:\n        importances.append([i-1,model.feature_importances_])\n    except AttributeError:\n        pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.732179Z","iopub.status.idle":"2025-05-03T18:48:54.733198Z","shell.execute_reply.started":"2025-05-03T18:48:54.733030Z","shell.execute_reply":"2025-05-03T18:48:54.733047Z"}},"outputs":[],"execution_count":null},{"id":"aging-johnson","cell_type":"code","source":"X_train = run_tsfresh(filtered_eegs1,labels1)\ny_train = labels1\nX_test = run_tsfresh(filtered_eegs2,labels2)\ny_test = labels2\nocolumns = X_train.columns\n\nscaler = preprocessing.MinMaxScaler()   # since the data set is not gaussian\nscaled_df = scaler.fit_transform(X_train)\nX_train = pd.DataFrame(scaled_df,columns = ocolumns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns = ocolumns)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.734213Z","iopub.status.idle":"2025-05-03T18:48:54.734510Z","shell.execute_reply.started":"2025-05-03T18:48:54.734359Z","shell.execute_reply":"2025-05-03T18:48:54.734372Z"}},"outputs":[],"execution_count":null},{"id":"circular-westminster","cell_type":"code","source":"# TRAINING ALL THE MODELS\n\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\ni=0\nimportances=[]\nfor model in models:\n    i+=1\n    try:\n        model.fit(X_train,y_train)\n    except Exception as e: print('Error in model.fit >>>',e)\n    try:\n        pred=model.predict(X_test)\n    except Exception as e: print('Error in model.predict >>>',e)\n    print(str(i)+'___'+str(model.__class__)+(100-len(str(model.__class__)))*'>'+'__',accuracy_score(y_test,pred))\n    try:\n        importances.append([i-1,model.feature_importances_])\n    except AttributeError:\n        pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.735479Z","iopub.status.idle":"2025-05-03T18:48:54.735789Z","shell.execute_reply.started":"2025-05-03T18:48:54.735628Z","shell.execute_reply":"2025-05-03T18:48:54.735642Z"}},"outputs":[],"execution_count":null},{"id":"skilled-dealing","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"technical-discretion","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ranging-danger","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"judicial-bangkok","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bound-milton","cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20, stratify = y)\n\nsvclassifier = SVC(gamma = 'auto')\n# C = 1.0, gamma = 1.0 for linear kernel - selected using GridSearchCV\n# C = 0.01, gamma = 100 for rbf kernel - selected using GridSearchCV\n\nsvclassifier.fit(X_train,y_train)\n\ny_pred = svclassifier.predict(X_test)\n#result = [y_pred[i] == y_test[i] for i in range(len(y_test))]\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(confusion_matrix(y_test,y_pred), annot=True, linewidths=.1, fmt= '.0f',ax=ax).set_ylim(4,0)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Actual Class\")\nplt.show()\nprint(list(y_test),list(y_pred))\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.736972Z","iopub.status.idle":"2025-05-03T18:48:54.737194Z","shell.execute_reply.started":"2025-05-03T18:48:54.737095Z","shell.execute_reply":"2025-05-03T18:48:54.737104Z"}},"outputs":[],"execution_count":null},{"id":"concrete-entrance","cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20, stratify = y)\n\nsvclassifier = SVC(kernel = 'rbf',C = 1, gamma = 1)\n# C = 1.0, gamma = 1.0 for linear kernel - selected using GridSearchCV\n# C = 0.01, gamma = 100 for rbf kernel - selected using GridSearchCV\n\nsvclassifier.fit(X_train,y_train)\n\ny_pred = svclassifier.predict(X_test)\n#result = [y_pred[i] == y_test[i] for i in range(len(y_test))]\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(confusion_matrix(y_test,y_pred), annot=True, linewidths=.1, fmt= '.0f',ax=ax).set_ylim(4,0)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Actual Class\")\nplt.show()\nprint(list(y_test),list(y_pred))\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:48:54.737779Z","iopub.status.idle":"2025-05-03T18:48:54.738065Z","shell.execute_reply.started":"2025-05-03T18:48:54.737936Z","shell.execute_reply":"2025-05-03T18:48:54.737946Z"}},"outputs":[],"execution_count":null},{"id":"passive-forge","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}